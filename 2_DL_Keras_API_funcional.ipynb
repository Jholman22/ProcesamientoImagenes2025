{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jholman22/ProcesamientoImagenes2025/blob/main/2_DL_Keras_API_funcional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O47Jrm_NPVav"
      },
      "source": [
        "# Creación de arquitecturas de aprendizaje profundo mediante API funcional de Keras.\n",
        "\n",
        "- Se presentan los consideraciones básicas respecto a la [API funcional de Keras](https://keras.io/guides/functional_api/) para la implementación de modelos de redes profundas con TensorFlow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d58EKYuBaWp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "964f0dce-0649-4597-8bd0-50093ade750c"
      },
      "source": [
        "import tensorflow as tf #importar tensorflow\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f9897a8cf341>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;31m#importar tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf_keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DO NOT EDIT. Generated by api_gen.sh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTypePolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloatDTypePolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/api/wrappers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSKLearnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SKLearnClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SKLearnRegressor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SKLearnTransformer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/sklearn_wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msklearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array_api_compat.numpy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    622\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 624\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   6017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6019\u001b[0;31m \u001b[0mlandau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandau_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'landau'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, seed)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                                   \u001b[0mlocscale_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loc=0, scale=1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m                                   locscale_out='loc, scale')\n\u001b[0;32m-> 1877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlongname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_attach_methods\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \"\"\"\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# _attach_methods is responsible for calling _attach_argparser_methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_argparser_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# nin correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_attach_argparser_methods\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \"\"\"\n\u001b[1;32m    734\u001b[0m         \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_arg_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;31m# NB: attach to the instance, not class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_parse_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_parse_args_stats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_parse_args_rvs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_115DWTKPyN4"
      },
      "source": [
        "- Se utilizará la base de datos Fashion Mnist nuevamente, normalizando las imágenes de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIH98kIYLp9D"
      },
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "images, labels = train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1e1mWxaP_Ay"
      },
      "source": [
        "- Se presenta un ejemplo de la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Z0VG9dOQ5X"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(images[5000,:,:],cmap= 'binary')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZK6zKgQOYjC"
      },
      "source": [
        "import numpy as np\n",
        "print(np.unique(labels)) #etiquetas\n",
        "print(images.shape) #tamaño de las imágenes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_IxEbq7Pi-j"
      },
      "source": [
        "Xtrain, ytrain = train\n",
        "Xtrain = Xtrain/255 # tipo flotante, normalizados de 0 a 1\n",
        "Xtest, ytest = test\n",
        "Xtest = Xtest/255 # tipo flotante, normalizados de 0 a 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML0rc-CtQUNZ"
      },
      "source": [
        "- En el cuaderno introductorio a redes neuronales con tensorflow se planteó la construcción de modelos mediante secuencia de capas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGjPUneLO81Z"
      },
      "source": [
        "#definir arquitectura secuencial\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2])),\n",
        "    tf.keras.layers.Dense(200,activation=\"relu\", name='red1'),\n",
        "    tf.keras.layers.Dense(50, activation=\"tanh\",name='hred2'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax',name='output')\n",
        "])\n",
        "\n",
        "model.summary() # resumen del modelo\n",
        "tf.keras.utils.plot_model(model) #diagrama del modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb1kJpU5Qg-h"
      },
      "source": [
        "- Aunque la implementacióm mediante secuencia es intuitiva, no permite realizar conexiones flexibles entre capas.\n",
        "\n",
        "- En ese sentido, Keras permite crear capas bajo el principio de funciones y argumentos, como se muestra a continuación.\n",
        "\n",
        "**Nota**: a diferencia de la estructura secuencial, en la API funcional se debe indicar la capa o capas de entrada y la capa o capas de salida para crear el grafo computacional de forma apropiada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5z1QP3KQbgH"
      },
      "source": [
        "#arquitectura funcional\n",
        "#capa de entrada\n",
        "input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1],Xtrain.shape[2]), name='entrada')\n",
        "#capa de aplanamiento de las imágenes\n",
        "flatten = tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2]))(input_l)#argumento de entrada\n",
        "#capas densas\n",
        "h1 = tf.keras.layers.Dense(200,activation='tanh',name='h1')(flatten)#argumento de entrada\n",
        "h2 = tf.keras.layers.Dense(50,activation='tanh',name='h2')(h1)\n",
        "#capa de salida\n",
        "output = tf.keras.layers.Dense(10,activation=\"softmax\",name='output')(h2)\n",
        "#crear modelo según conexiones tipo funcionales\n",
        "model_fun = tf.keras.Model(inputs=input_l,outputs=output)\n",
        "\n",
        "#resumen y gráfica del modelo\n",
        "model_fun.summary()\n",
        "tf.keras.utils.plot_model(model_fun)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QGmICK83p__"
      },
      "source": [
        "# La API funcional permite realizar conexiones más flexibles\n",
        "\n",
        "- En el siguiente ejemplo se crea un modelo con una entrada y dos salidas con interconexiones flexibles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0D9MaQUUC5S"
      },
      "source": [
        "#arquitectura funcional 2\n",
        "tf.keras.backend.clear_session()\n",
        "input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1],Xtrain.shape[2]), name='entrada')\n",
        "flatten = tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2]))(input_l)\n",
        "\n",
        "h1 = tf.keras.layers.Dense(200,activation='tanh',name='h1')(flatten)\n",
        "h2 = tf.keras.layers.Dense(50,activation='tanh',name='h2')(h1)\n",
        "#capa que concatena caracterísitacas extraídas en h2 con imágenes de entrada\n",
        "concat = tf.keras.layers.concatenate([h2,flatten])\n",
        "#se crean dos salidas:\n",
        "output_A = tf.keras.layers.Dense(10,activation=\"softmax\",name='outputA')(concat)#desde concatenación\n",
        "output_B = tf.keras.layers.Dense(10,activation=\"softmax\",name='outputB')(h2)#desde h2\n",
        "#las entradas y salidas se ingresan como listas\n",
        "model_fun = tf.keras.Model(inputs=input_l,outputs=[output_A, output_B])\n",
        "#model_fun.summary()\n",
        "tf.keras.utils.plot_model(model_fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgCBNFKlRh7S"
      },
      "source": [
        "**Nota**: si se cuenta con varias salidas se puede definir un mismo costo para cada salida, o una lista con los costos requeridos. Además, en la lista `loss_weights` se puede especificar el valor del peso asociado al costo de cada salida en el intervalo [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqRy7EUlWe8W"
      },
      "source": [
        "model_fun.compile(loss=\"sparse_categorical_crossentropy\", #custom_loss(),#custom_loss(),#\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\",\"accuracy\"]) #f1, precision, recall, crossentropy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G5VnJpYZJ-d"
      },
      "source": [
        "- El entrenamiento se realiza de igual forma al utilizado con el modelo secuencial.\n",
        "\n",
        "- Como se fijaron dos salidas, se debe ingresar una lista para los argumentos ytrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_7oCxbYmgG"
      },
      "source": [
        "history = model_fun.fit(Xtrain, [ytrain,ytrain] , epochs=10,batch_size=64, # 32, 64, 128, 256\n",
        "                    validation_split=0.3) # se fija el conjunto de validación como el 20% del de train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIkCfKwAZRG_"
      },
      "source": [
        "- Se presentan las curvas de desempeño:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKQn2C8nY3wR"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "#save_fig(\"keras_learning_curves_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhSy80mGZVoY"
      },
      "source": [
        "- Como el modelo generado presenta dos salidas, el rendimiento se discrimina por cada salida y el acumulado.\n",
        "\n",
        "- A la hora de predecir la salida para una nueva muestra, se debe tener en cuenta la cantidad de salidas fijadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKsIK96KZPpi"
      },
      "source": [
        "yestA,yestB = model_fun.predict(Xtest)\n",
        "print(yestA.shape,yestB.shape)#salidas tipo 1 -K probabilidad de membresia a cada clase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8RBO0NNaJdK"
      },
      "source": [
        "print(yestA[0].argmax(),ytest[0])#para estimar la etiqueta ordinal se encuentra el max por columnas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuKDvDJtabCQ"
      },
      "source": [
        "scoreA = model_fun.evaluate(Xtest,[ytest,ytest])#evaluacion\n",
        "print(scoreA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR9fa_JS3wiR"
      },
      "source": [
        "# Grafiquemos los pesos respecto a las dimensiones de la imagen original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voOY0whlaKWf"
      },
      "source": [
        "#se busca identificar las entradas más relevantes para la red\n",
        "plt.imshow(abs(model.layers[1].get_weights()[0]).sum(axis=1).reshape(28,28))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDoNdsXwa1Qa"
      },
      "source": [
        "model.layers[1].get_weights()[1].shape # accediendo a los bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XVwO-Q_3uoJ"
      },
      "source": [
        "# Salidas parciales de la red\n",
        "\n",
        "- La estrategia funcional nos permite acceder a partes intermedias de la red para encontrar mapas de características y verificar el aprendizaje de la representación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztzzh2ggcs59"
      },
      "source": [
        "#crear nuevo modelo con salida parcial\n",
        "model_B = tf.keras.Model(inputs=model_fun.inputs,outputs=model_fun.get_layer('h2').output) #se accede a capas por nombre\n",
        "tf.keras.utils.plot_model(model_B) # modelo ya esta ajustado!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_F5ldNl4B8B"
      },
      "source": [
        "z = model_B.predict(Xtest) # salida en h2\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdorTICc39Op"
      },
      "source": [
        "### Dado que se fijaron 50 unidades, se pueden utilizar técnicas de reducción de dimensión para visualizar los patrones intermedios de la red en 2D.\n",
        "\n",
        "\n",
        "# Principal Component Analysis (PCA)\n",
        "\n",
        "Reducción de dimensión lineal basado en la preservación de la varianza\n",
        "\n",
        "![PCA1](https://www.soloentendidos.com/wp-content/uploads/2021/06/Principal-Component-Analysis-second-principal_thumb-1.gif)\n",
        "\n",
        "\n",
        "![PCA2](https://1.bp.blogspot.com/-pgMAHiIWvuw/Tql5HIXNdRI/AAAAAAAABLI/I2zPF5cLRwQ/s1600/clust.gif)\n",
        "\n",
        "\n",
        "# t-student distributed Stochastic Neighbor Embedding (t-SNE)\n",
        "\n",
        "Reducción de dimensión basado en la preservación de localidades (vecinos) utilizando medidas de información desde estimación no paramétrica de probabilidad en el espación de alta y baja dimensión, respectivamente.\n",
        "\n",
        "![tsne](https://learnopencv.com/wp-content/uploads/2022/11/tsne.gif)\n",
        "\n",
        "![tsne2](https://3.bp.blogspot.com/-NE01azL_JxU/Wxli17oYNzI/AAAAAAAACxQ/axOI2yy-Ft0QbqaekOyemm5Xn0wAFvRUwCLcBGAs/s640/image2.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SbDU2ue4UTi"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "zpca = PCA(n_components=2).fit_transform(z)\n",
        "zpca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz4TtdMu6S_M"
      },
      "source": [
        "plt.scatter(zpca[:,0],zpca[:,1],c=ytest)\n",
        "plt.colorbar()\n",
        "plt.xlabel('componente 1')\n",
        "plt.ylabel('componente 2')\n",
        "plt.title('PCA atributos extraídos en capa h2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUPQ3fy_6iCF"
      },
      "source": [
        "#plot mnist 2D\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "def plot_mnist_2d(Z,y,images,img_w=28,img_h=28,zoom=0.5,cmap='jet'):\n",
        "    fig, ax = plt.subplots(figsize=(16,10))\n",
        "    for i in range(Z.shape[0]):\n",
        "        #print('img',i+1,'/',Z.shape[0])\n",
        "        image = images[i].reshape((img_w, img_h))\n",
        "        im = OffsetImage(image, zoom=zoom,cmap=cmap)\n",
        "        ab = AnnotationBbox(im, (Z[i,0], Z[i,1]), xycoords='data', frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "        ax.update_datalim([(Z[i,0], Z[i,1])])\n",
        "        ax.autoscale()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDRcBMOlbjHD"
      },
      "source": [
        "- También, podemos revisar la distribución de las imágenes en el espacio proyectado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmtPGNsp6pI-"
      },
      "source": [
        "Ni =4000 # graficar Ni muestras como imagenes en espacio 2D\n",
        "ind = np.random.randint(0,ytest.shape[0],Ni)\n",
        "plot_mnist_2d(zpca[ind],ytest[ind],Xtest[ind],img_w=28,img_h=28,zoom=0.5,cmap='binary')\n",
        "plt.xlabel('componente 1')\n",
        "plt.ylabel('componente 2')\n",
        "plt.title('PCA atributos extraídos en capa h2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA5nkj4HbyKB"
      },
      "source": [
        "# Ejercicio:\n",
        "\n",
        "- Grafique el espacio proyectado de PCA en 2D (etiquetas e imágenes) para los atributos aprendidos por la capa de concatenación.\n",
        "\n",
        "- Repita el proceso aplicando la técnica de reducción de dimensión [UMAP de RAPIDS](https://developer.nvidia.com/blog/even-faster-and-more-scalable-umap-on-the-gpu-with-rapids-cuml/).\n",
        "\n",
        "- Plantee una nueva arquitectura tipo funcional utilizando capas convolucionales (Ver cuaderno [CNNs](https://github.com/amalvarezme/AprendizajeMaquina/blob/main/5_DeepLearning/3_Introduccion_CNN.ipynb)) para el entrenamiento de la base de datos Mnist-digitos, utilizando tres entradas: i) imágenes limpias, ii) y iii) imágenes con ruido blanco Gaussiano ante diferentes varianzas, y dos salidas i) estimación del digito, ii) estimación número par número impar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot0hgm216udN"
      },
      "source": [
        "#Ayuda de código:\n",
        "#cargar fashion mnist o mnist\n",
        "#(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train, X_valid = X_train[:-55000], X_train[-55000:]\n",
        "y_train, y_valid = y_train[:-55000], y_train[-55000:]\n",
        "\n",
        "X_train = X_train[..., np.newaxis]/255.\n",
        "X_valid = X_valid[..., np.newaxis]/255.\n",
        "X_test = X_test[..., np.newaxis]/255.\n",
        "print(X_train.shape,X_valid.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucYaiCQduwy"
      },
      "source": [
        "#crear entradas con y sin ruido\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "var_ = [0.01,0.25]\n",
        "inputs_train = [X_train]\n",
        "inputs_valid = [X_valid]\n",
        "inputs_test = [X_test]\n",
        "\n",
        "#recorrer varianzas\n",
        "for var_i in var_:\n",
        "    dim = X_train.shape\n",
        "    #definir ruido\n",
        "    tmp = X_train + (np.sqrt(var_i)*np.random.randn(X_train.shape[0],dim[1],dim[2],dim[3]))\n",
        "    tmp = MinMaxScaler().fit_transform(tmp.reshape(dim[0],-1).T).T #fijar señal con ruido de 0 a 1\n",
        "    inputs_train += [tmp.reshape(dim)]\n",
        "\n",
        "    dim = X_valid.shape\n",
        "    tmp = X_valid + (np.sqrt(var_i)*np.random.randn(X_valid.shape[0],dim[1],dim[2],dim[3]))\n",
        "    tmp = MinMaxScaler().fit_transform(tmp.reshape(dim[0],-1).T).T\n",
        "    inputs_valid += [tmp.reshape(dim)]\n",
        "\n",
        "    dim = X_test.shape\n",
        "    tmp = X_test + (np.sqrt(var_i)*np.random.randn(X_test.shape[0],dim[1],dim[2],dim[3]))\n",
        "    tmp = MinMaxScaler().fit_transform(tmp.reshape(dim[0],-1).T).T\n",
        "    inputs_test += [tmp.reshape(dim)]\n",
        "\n",
        "\n",
        "plt.imshow(np.c_[inputs_train[0][0,:,:,0],inputs_train[1][0,:,:,0],inputs_train[2][0,:,:,0]])\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj71cQCIeXen"
      },
      "source": [
        "#veector de salida par o impar\n",
        "ytrain_B = (ytrain % 2)\n",
        "print(ytrain_B[10:])\n",
        "print(ytrain[10:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incuTjIbfKj5"
      },
      "source": [
        "#arquitectura funcional 2 - Ayuda de código con capas densas - cambiar a capas cnn\n",
        "tf.keras.backend.clear_session()\n",
        "input_1 = tf.keras.layers.Input(shape=(Xtrain.shape[1],Xtrain.shape[2]), name='entrada_1')\n",
        "input_2 = tf.keras.layers.Input(shape=(Xtrain.shape[1],Xtrain.shape[2]), name='entrada_2')\n",
        "input_3 = tf.keras.layers.Input(shape=(Xtrain.shape[1],Xtrain.shape[2]), name='entrada_3')\n",
        "\n",
        "flatten_1 = tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2]))(input_1)\n",
        "flatten_2 = tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2]))(input_2)\n",
        "flatten_3 = tf.keras.layers.Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2]))(input_3)\n",
        "\n",
        "h1_1 = tf.keras.layers.Dense(200,activation='tanh',name='h1_1')(flatten_1)\n",
        "h2_1 = tf.keras.layers.Dense(50,activation='tanh',name='h2_1')(h1_1)\n",
        "\n",
        "h1_2 = tf.keras.layers.Dense(200,activation='tanh',name='h1_2')(flatten_2)\n",
        "h2_2 = tf.keras.layers.Dense(50,activation='tanh',name='h2_2')(h1_2)\n",
        "\n",
        "h1_3 = tf.keras.layers.Dense(200,activation='tanh',name='h1_3')(flatten_3)\n",
        "h2_3 = tf.keras.layers.Dense(50,activation='tanh',name='h2_3')(h1_3)\n",
        "\n",
        "#capa que concatena caracterísitacas extraídas en h2 con imágenes de entrada\n",
        "concat = tf.keras.layers.concatenate([h2_1,h2_2,h2_3])\n",
        "#se crean dos salidas:\n",
        "output_d = tf.keras.layers.Dense(10,activation=\"softmax\",name='output_d')(concat)#desde concatenación\n",
        "output_p = tf.keras.layers.Dense(1,activation=\"sigmoid\",name='output_p')(concat)#desde h2\n",
        "#las entradas y salidas se ingresan como listas\n",
        "model_fun2 = tf.keras.Model(inputs=[input_1,input_2,input_3],outputs=[output_d, output_p])\n",
        "#model_fun.summary()\n",
        "tf.keras.utils.plot_model(model_fun2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgwWR-2DsScZ"
      },
      "source": [
        "#Entrenar y ajustar el modelo, revisar rendimientos en cada salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn -q\n"
      ],
      "metadata": {
        "id": "cfXsMpHzovf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Punto 1"
      ],
      "metadata": {
        "id": "H9c2qnCTlyqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al comparar las salidas de las capas flatten, h1, h2, outputA y outputB se nota cómo el modelo va aprendiendo progresivamente a representar mejor los datos, en flatten las imágenes están aplanadas y no hay una estructura clara, las clases están mezcladas y no se distinguen bien. En h1 empiezan a formarse agrupaciones lo que indica que la red ya está captando algunas características. En h2 esas agrupaciones se vuelven más definidas y muestran una organización entre diferentes tipos de prendas. OutputA presenta una separación aún más marcada entre clases ya que se basa en una combinación más rica de información. OutputB también logra una buena organización aunque refleja más directamente lo aprendido en las capas ocultas sin la ayuda de las entradas originales."
      ],
      "metadata": {
        "id": "cC-hEsoLmSms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "jKWzj-RQ1ITd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Punto 2"
      ],
      "metadata": {
        "id": "GkdgnOI3miUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo parcial con salida en la capa de concatenación\n",
        "model_concat = tf.keras.Model(inputs=model_fun2.inputs,\n",
        "                              outputs=model_fun2.get_layer('concatenate').output)\n",
        "\n",
        "# Obtener la salida de la capa\n",
        "Z_concat = model_concat.predict([X_test, X_test, X_test])\n",
        "print(Z_concat.shape)\n"
      ],
      "metadata": {
        "id": "Y5_ulHQthOka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "Z_concat_pca = PCA(n_components=2).fit_transform(Z_concat)\n",
        "print(Z_concat_pca.shape)\n"
      ],
      "metadata": {
        "id": "jHpv1sIQnN2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(Z_concat_pca[:,0], Z_concat_pca[:,1], c=y_test, cmap='tab10', s=10, alpha=0.8)\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Componente 1\")\n",
        "plt.ylabel(\"Componente 2\")\n",
        "plt.title(\"PCA atributos extraídos en capa de concatenación\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PxOrjAdvnST6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "def plot_mnist_2d(Z, y, images, img_w=28, img_h=28, zoom=0.5, cmap='binary'):\n",
        "    fig, ax = plt.subplots(figsize=(16, 10))\n",
        "    for i in range(Z.shape[0]):\n",
        "        image = images[i].reshape((img_w, img_h))\n",
        "        im = OffsetImage(image, zoom=zoom, cmap=cmap)\n",
        "        ab = AnnotationBbox(im, (Z[i, 0], Z[i, 1]), xycoords='data', frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "        ax.update_datalim([(Z[i, 0], Z[i, 1])])\n",
        "        ax.autoscale()\n",
        "\n",
        "Ni = 4000\n",
        "ind = np.random.randint(0, X_test.shape[0], Ni)\n",
        "plot_mnist_2d(Z_concat_pca[ind], y_test[ind], X_test[ind], zoom=0.5)\n",
        "plt.xlabel('componente 1')\n",
        "plt.ylabel('componente 2')\n",
        "plt.title('PCA atributos extraídos en capa de concatenación')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "As4NyDeonVZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "Z_concat_scaled = StandardScaler().fit_transform(Z_concat)\n",
        "\n",
        "umap_model = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
        "Z_concat_umap = umap_model.fit_transform(Z_concat_scaled)\n"
      ],
      "metadata": {
        "id": "nBegJzyxo0VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(Z_concat_umap[:,0], Z_concat_umap[:,1], c=y_test, cmap='tab10', s=10, alpha=0.8)\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.title(\"UMAP atributos extraídos en capa de concatenación\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h1D9l1xUqTZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ni = 4000\n",
        "ind = np.random.randint(0, X_test.shape[0], Ni)\n",
        "plot_mnist_2d(Z_concat_umap[ind], y_test[ind], X_test[ind], zoom=0.5)\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.title(\"UMAP atributos extraídos en capa de concatenación\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cx8n90JPqns4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN"
      ],
      "metadata": {
        "id": "yb70dw_yrDM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Entradas\n",
        "input_1 = tf.keras.layers.Input(shape=(28, 28, 1), name='entrada_limpia')\n",
        "input_2 = tf.keras.layers.Input(shape=(28, 28, 1), name='entrada_ruido_1')\n",
        "input_3 = tf.keras.layers.Input(shape=(28, 28, 1), name='entrada_ruido_2')\n",
        "\n",
        "# Bloque CNN para cada entrada\n",
        "def cnn_branch(x, name):\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name=f'conv1_{name}')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), name=f'pool1_{name}')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name=f'conv2_{name}')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), name=f'pool2_{name}')(x)\n",
        "    x = tf.keras.layers.Flatten(name=f'flat_{name}')(x)\n",
        "    return x\n",
        "\n",
        "# Procesamiento de cada entrada\n",
        "branch_1 = cnn_branch(input_1, \"b1\")\n",
        "branch_2 = cnn_branch(input_2, \"b2\")\n",
        "branch_3 = cnn_branch(input_3, \"b3\")\n",
        "\n",
        "# Concatenación de los tres vectores\n",
        "concat = tf.keras.layers.concatenate([branch_1, branch_2, branch_3], name='concatenate')\n",
        "\n",
        "# Capa densa común\n",
        "fc = tf.keras.layers.Dense(128, activation='relu', name='fc_concat')(concat)\n",
        "drop = tf.keras.layers.Dropout(0.3)(fc)\n",
        "\n",
        "# Salida 1: dígito (10 clases)\n",
        "output_d = tf.keras.layers.Dense(10, activation='softmax', name='output_d')(drop)\n",
        "\n",
        "# Salida 2: par/impar (1 salida binaria)\n",
        "output_p = tf.keras.layers.Dense(1, activation='sigmoid', name='output_p')(drop)\n",
        "\n",
        "# Modelo final\n",
        "model_cnn = tf.keras.Model(inputs=[input_1, input_2, input_3],\n",
        "                           outputs=[output_d, output_p])\n",
        "\n",
        "tf.keras.utils.plot_model(model_cnn, show_shapes=True)\n",
        "model_cnn.summary()\n"
      ],
      "metadata": {
        "id": "PgIapgxwrIdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(\n",
        "    loss={'output_d': 'sparse_categorical_crossentropy',\n",
        "          'output_p': 'binary_crossentropy'},\n",
        "    optimizer='adam',\n",
        "    metrics={'output_d': 'accuracy', 'output_p': 'accuracy'}\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "history = model_cnn.fit(\n",
        "    [inputs_train[0], inputs_train[1], inputs_train[2]],\n",
        "    [y_train, y_train % 2],\n",
        "    validation_data=([inputs_valid[0], inputs_valid[1], inputs_valid[2]], [y_valid, y_valid % 2]),\n",
        "    epochs=10,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "tsD5YfgkrLDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(\n",
        "    loss={'output_d': 'sparse_categorical_crossentropy',\n",
        "          'output_p': 'binary_crossentropy'},\n",
        "    optimizer='adam',\n",
        "    metrics={'output_d': 'accuracy', 'output_p': 'accuracy'}\n",
        ")\n",
        "\n",
        "# Entrenamiento (X_train1, X_train2, X_train3 deben estar normalizados)\n",
        "history = model_cnn.fit(\n",
        "    [inputs_train[0], inputs_train[1], inputs_train[2]],\n",
        "    [y_train, y_train % 2],\n",
        "    validation_data=([inputs_valid[0], inputs_valid[1], inputs_valid[2]], [y_valid, y_valid % 2]),\n",
        "    epochs=10,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "N-6ryxLsroaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_concat_cnn = tf.keras.Model(inputs=model_cnn.inputs,\n",
        "                                  outputs=model_cnn.get_layer('concatenate').output)\n",
        "\n",
        "\n",
        "Z_cnn = model_concat_cnn.predict([inputs_test[0], inputs_test[1], inputs_test[2]])\n",
        "print(\"Shape salida 'concatenate':\", Z_cnn.shape)\n"
      ],
      "metadata": {
        "id": "piL6AL-KsB1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "Z_cnn_pca = PCA(n_components=2).fit_transform(Z_cnn)\n",
        "print(\"Shape PCA:\", Z_cnn_pca.shape)\n"
      ],
      "metadata": {
        "id": "XF1uOkGHsJeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "Z_cnn_scaled = StandardScaler().fit_transform(Z_cnn)\n",
        "\n",
        "umap_model = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
        "Z_cnn_umap = umap_model.fit_transform(Z_cnn_scaled)\n"
      ],
      "metadata": {
        "id": "b89uQUwjsMu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(Z_cnn_pca[:,0], Z_cnn_pca[:,1], c=y_test, cmap='tab10', s=10, alpha=0.8)\n",
        "plt.colorbar()\n",
        "plt.title(\"PCA sobre salida concatenada - CNN\")\n",
        "plt.xlabel(\"Componente 1\")\n",
        "plt.ylabel(\"Componente 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N0Q21lOKsPMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(Z_cnn_umap[:,0], Z_cnn_umap[:,1], c=y_test, cmap='tab10', s=10, alpha=0.8)\n",
        "plt.colorbar()\n",
        "plt.title(\"UMAP sobre salida concatenada - CNN\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SGL4iZR3seET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar en conjunto de prueba\n",
        "eval_result = model_cnn.evaluate(\n",
        "    [inputs_test[0], inputs_test[1], inputs_test[2]],\n",
        "    [y_test, y_test % 2],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nMétricas en test:\")\n",
        "print(f\"Pérdida total:        {eval_result[0]:.4f}\")\n",
        "print(f\"Pérdida dígito (0–9): {eval_result[1]:.4f}\")\n",
        "print(f\"Accuracy dígito:      {eval_result[3]:.4f}\")\n",
        "print(f\"Pérdida par/impar:    {eval_result[2]:.4f}\")\n",
        "print(f\"Accuracy par/impar:   {eval_result[4]:.4f}\")\n"
      ],
      "metadata": {
        "id": "6X3dv0P3siBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}